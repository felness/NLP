{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMR2ahkte_7m"
      },
      "source": [
        "# Импортируем нужные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdeBkvJFfEPO"
      },
      "outputs": [],
      "source": [
        "from gigachat import GigaChat\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "import os\n",
        "from getpass import getpass\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSaG48B2fGRL"
      },
      "source": [
        "# Парсинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxC9DyR_dqkn"
      },
      "source": [
        "Основная логика парсинга:\n",
        "\n",
        "1) делаем запрос к ArXiv API  используя параметры поиска, я выбрал  ключевые слова (\"video generation\", \"video synthesis\") и категории (cs.CV, cs.AI). Для пагинации  используется параметр , который увеличивается на размер страницы после каждого запроса. Это нужно чтобы предотвратить дублирование и получить большее количество статей.\n",
        "\n",
        "2) Далее фильтруем статьи по году и загружаем их метаданные в датафрейм для дальнейшего использования.\n",
        "\n",
        "\n",
        "Я собираю не только метаданные, но и сами тексты аннотаций, которые необходимы для последующего использования.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU7ecmDZdlAR",
        "outputId": "ad15c1e4-f29c-4b69-8918-8cc76935be7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Достигнут конец списка статей.\n"
          ]
        }
      ],
      "source": [
        "def fetch_arxiv_metadata_with_pagination(query, max_results_per_request=500):\n",
        "    all_articles = []\n",
        "    start = 0\n",
        "    step = max_results_per_request\n",
        "\n",
        "    while True:\n",
        "        url = f\"http://export.arxiv.org/api/query?search_query={query}&start={start}&max_results={step}\"\n",
        "        feed = feedparser.parse(url)\n",
        "\n",
        "        articles = []\n",
        "        for entry in feed.entries:\n",
        "            published = datetime.strptime(entry.published, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "            published_year = published.year\n",
        "\n",
        "            if published_year != 2024:\n",
        "                continue\n",
        "\n",
        "            article_data = {\n",
        "                'title': entry.title,\n",
        "                'annotation': entry.summary,\n",
        "                'year': published,\n",
        "                'categories': [tag['term'] for tag in entry.tags],\n",
        "                'url': entry.link\n",
        "            }\n",
        "            articles.append(article_data)\n",
        "\n",
        "        all_articles.extend(articles)\n",
        "\n",
        "        if len(feed.entries) < step:\n",
        "            print(\"Достигнут конец списка статей.\")\n",
        "            break\n",
        "\n",
        "        start += step\n",
        "\n",
        "    df = pd.DataFrame(all_articles)\n",
        "    return df\n",
        "\n",
        "query = \"video+generation+OR+video+synthesis+OR+generative+video+OR+text-to-video+cat:cs.CV+OR+cat:cs.AI+submittedDate:[20240101+TO+20241231]\"\n",
        "meta_data = fetch_arxiv_metadata_with_pagination(query, max_results_per_request=500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bglJpAFGdlAU"
      },
      "source": [
        "Из большого множества парсеров я выбрал  feedparser, потому что API ArXiv возвращает данные в формате Atom/RSS, который этот пакет прекрасно обрабатывает. Этот подход также упрощает работу с пагинацией, поскольку нам нужно последовательно запрашивать данные небольшими частями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex8S3qjQdlAV",
        "outputId": "c0dd1ba0-264c-4858-e468-064d076ab27d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1258"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(meta_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4OZtxHDdlAW",
        "outputId": "7c14e84d-2666-4196-f081-b5f19b3a14bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>annotation</th>\n",
              "      <th>year</th>\n",
              "      <th>categories</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fine-gained Zero-shot Video Sampling</td>\n",
              "      <td>Incorporating a temporal dimension into pretra...</td>\n",
              "      <td>2024-07-31 09:36:58</td>\n",
              "      <td>[cs.CV, cs.AI]</td>\n",
              "      <td>http://arxiv.org/abs/2407.21475v1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Factorized-Dreamer: Training A High-Quality Vi...</td>\n",
              "      <td>Text-to-video (T2V) generation has gained sign...</td>\n",
              "      <td>2024-08-19 16:08:00</td>\n",
              "      <td>[cs.CV, cs.AI]</td>\n",
              "      <td>http://arxiv.org/abs/2408.10119v1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SpatialDreamer: Self-supervised Stereo Video S...</td>\n",
              "      <td>Stereo video synthesis from a monocular input ...</td>\n",
              "      <td>2024-11-18 15:12:59</td>\n",
              "      <td>[cs.CV, cs.AI]</td>\n",
              "      <td>http://arxiv.org/abs/2411.11934v1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Snap Video: Scaled Spatiotemporal Transformers...</td>\n",
              "      <td>Contemporary models for generating images show...</td>\n",
              "      <td>2024-02-22 18:55:08</td>\n",
              "      <td>[cs.CV, cs.AI]</td>\n",
              "      <td>http://arxiv.org/abs/2402.14797v1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SNED: Superposition Network Architecture Searc...</td>\n",
              "      <td>While AI-generated content has garnered signif...</td>\n",
              "      <td>2024-05-31 21:12:30</td>\n",
              "      <td>[cs.CV, cs.AI]</td>\n",
              "      <td>http://arxiv.org/abs/2406.00195v1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0               Fine-gained Zero-shot Video Sampling   \n",
              "1  Factorized-Dreamer: Training A High-Quality Vi...   \n",
              "2  SpatialDreamer: Self-supervised Stereo Video S...   \n",
              "3  Snap Video: Scaled Spatiotemporal Transformers...   \n",
              "4  SNED: Superposition Network Architecture Searc...   \n",
              "\n",
              "                                          annotation                year  \\\n",
              "0  Incorporating a temporal dimension into pretra... 2024-07-31 09:36:58   \n",
              "1  Text-to-video (T2V) generation has gained sign... 2024-08-19 16:08:00   \n",
              "2  Stereo video synthesis from a monocular input ... 2024-11-18 15:12:59   \n",
              "3  Contemporary models for generating images show... 2024-02-22 18:55:08   \n",
              "4  While AI-generated content has garnered signif... 2024-05-31 21:12:30   \n",
              "\n",
              "       categories                                url  \n",
              "0  [cs.CV, cs.AI]  http://arxiv.org/abs/2407.21475v1  \n",
              "1  [cs.CV, cs.AI]  http://arxiv.org/abs/2408.10119v1  \n",
              "2  [cs.CV, cs.AI]  http://arxiv.org/abs/2411.11934v1  \n",
              "3  [cs.CV, cs.AI]  http://arxiv.org/abs/2402.14797v1  \n",
              "4  [cs.CV, cs.AI]  http://arxiv.org/abs/2406.00195v1  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKAt8CMDg8q_"
      },
      "source": [
        "# Выделение трендов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKuKJQemdlAW"
      },
      "source": [
        "Итак с помощью пагинации нам удалось собрать 1258 методанных статей и их аннотации  по теме видеогенерация в 2024 году.\n",
        "Далее я буду вычленять из них ключевые слова (исключая стоп слова), разбивать их по темам и выделять тренды, для этого я буду использовать tf-idf и кластеризацию k-средних, параметр k буду подбирать на основе silhouette_score для выделения оптимального количества трендов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF-j6S03dlAW"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "custom_stop_words = ['video', 'generation', 'model', 'models', 'using', 'based']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMh30aqOdlAX"
      },
      "outputs": [],
      "source": [
        "def extract_keywords(text):\n",
        "    doc = nlp(text)\n",
        "    keywords = [token.text.lower() for token in doc if token.pos_ in ['NOUN', 'ADJ', 'VERB'] and not token.is_stop and token.text.lower() not in custom_stop_words]\n",
        "    noun_phrases = [chunk.text.lower() for chunk in doc.noun_chunks if len(chunk.text.split()) > 1 and chunk.text.lower() not in custom_stop_words]\n",
        "    return keywords + noun_phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK6QvxYldlAX"
      },
      "outputs": [],
      "source": [
        "all_keywords = []\n",
        "for abstract in meta_data['annotation']:\n",
        "    keywords = extract_keywords(abstract)\n",
        "    all_keywords.extend(keywords)\n",
        "\n",
        "keyword_counts = Counter(all_keywords)\n",
        "\n",
        "top_keywords = [word for word, count in keyword_counts.most_common(100)]\n",
        "\n",
        "vectorizer = TfidfVectorizer(vocabulary=top_keywords, stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(meta_data['annotation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTvlbbthdlAX",
        "outputId": "e8fe9be9-b81f-48ba-c13f-83543fb3ceb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_k: 7\n"
          ]
        }
      ],
      "source": [
        "silhouette_scores = []\n",
        "for k in range(3, 10):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    clusters = kmeans.fit_predict(tfidf_matrix)\n",
        "    score = silhouette_score(tfidf_matrix, clusters)\n",
        "    silhouette_scores.append((k, score))\n",
        "\n",
        "best_k = max(silhouette_scores, key=lambda x: x[1])[0]\n",
        "print(f\"best_k: {best_k}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfuwR9EedlAX"
      },
      "source": [
        "После кластеризации я буду использовать llm (gigachat) для генерации на основе ключевых слов связанного тренда."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrLVz01fdlAX"
      },
      "outputs": [],
      "source": [
        "llm = GigaChat(\n",
        "    credentials=getpass('INSERT_AUTH.KEY:'),\n",
        "    model=\"GigaChat-Max\",\n",
        "    verify_ssl_certs=False)\n",
        "\n",
        "template = \"\"\"\n",
        "Твоя задача — описать тренд видеогенерации  на русском языке в виде короткого связного предложения с использованием ключевых слов.\n",
        "Предложение должно быть четким, длиной ровно 5–7 слов, без лишних слов.\n",
        "Используйте 2–3 ключевых слова из списка, связав их логически.\n",
        "\n",
        "Пример хорошего тренда: Генерация 3D-видео по аудиомоделям\n",
        "Пример плохого тренда: Генерация видео 3D аудиомодели\n",
        "\n",
        "Ключевые слова: {keywords}\n",
        "\n",
        "Сформулируйте тренд:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwIZ9h7bdlAY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "num_clusters = best_k\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "clusters = kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "meta_data['cluster'] = clusters\n",
        "\n",
        "def get_cluster_keywords(cluster_id):\n",
        "    cluster_abstracts = meta_data[meta_data['cluster'] == cluster_id]['annotation']\n",
        "    cluster_keywords = []\n",
        "    for abstract in cluster_abstracts:\n",
        "        keywords = extract_keywords(abstract)\n",
        "        cluster_keywords.extend(keywords)\n",
        "    return Counter(cluster_keywords).most_common(10)\n",
        "\n",
        "trends = []\n",
        "for i in range(num_clusters):\n",
        "    top_words = get_cluster_keywords(i)\n",
        "    keywords = ', '.join(word for word, _ in top_words[:5])\n",
        "\n",
        "    prompt = PromptTemplate(input_variables=['keywords'], template=template).format(keywords=keywords)\n",
        "    response = llm.chat(prompt).choices[0].message.content\n",
        "\n",
        "    word_count = len(response.split())\n",
        "    trends.append(response)\n",
        "\n",
        "result = pd.DataFrame({'Trends': trends})\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmEe9e01hA-z"
      },
      "source": [
        "# Результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0x1fgYBdlAY",
        "outputId": "7c52d799-4644-46c3-8f25-1ab9f24a82c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тренд №1: Генерация временных видеофреймов на основе данных\n",
            "Тренд №2: Улучшение качества видеодиффузии по текстовым и визуальным данным.\n",
            "Тренд №3: Генерация видео на основе понимания языка\n",
            "Тренд №4: Детекция объектов в видеороликах.\n",
            "Тренд №5: Генерация видео с говорящими визуальными моделями\n",
            "Тренд №6: Текстовая генерация видео с контролем движения\n",
            "Тренд №7: Генерация 3D-сцен с мультивидами\n"
          ]
        }
      ],
      "source": [
        "for i, trend in enumerate(result['Trends']):\n",
        "    print(f'Тренд №{i + 1}: {trend}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Видим, что тренды получились весьма обоснованными и действительно отражают актуальные направления в области видеогенерации и анализа видео."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sMR2ahkte_7m",
        "WSaG48B2fGRL",
        "tKAt8CMDg8q_",
        "OmEe9e01hA-z"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
